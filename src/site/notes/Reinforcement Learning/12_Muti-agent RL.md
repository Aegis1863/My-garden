---
{"dg-publish":true,"permalink":"/reinforcement-learning/12-muti-agent-rl/","dgPassFrontmatter":true,"created":"2024-01-10T10:29:37.368+08:00"}
---

代码  [19\_多智能体.ipynb](https://github.com/Aegis1863/ML_practice/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/19_%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93.ipynb)

# 1. 多智能体基础

多智能体条件下，环境是非稳态的，每个智能体都在改变环境，所以转移概率也可能经常变化。

* 完全中心化（fully centralized）方法：将多个智能体进行决策当作一个超级智能体在进行决策，即把所有智能体的状态聚合在一起当作一个全局的超级状态，把所有智能体的动作连起来作为一个联合动作，好处是环境仍然是稳态的，收敛性有保证，但是状态空间或者动作空间太大可能导致维度爆炸。

* 完全去中心化（fully decentralized）：假设每个智能体都在自身的环境中独立地进行学习，不考虑其他智能体的改变。每个智能体单独采用一个强化算法训练，但是环境非稳态，收敛性不能保证。

代码中仍然可以定义 PPO 或者其他算法，在训练时，建立多个智能体，每个智能体单独用一个 transition 表即可。

## 1.1. 中心化训练去中心化执行(CTDE)

这是指在训练的时候使用一些单个智能体看不到的全局信息而以达到更好的训练效果，而在执行时不使用这些信息，每个智能体完全根据自己的策略直接动作以达到去中心化执行的效果。

中心化训练去中心化执行的算法能够在训练时有效地利用全局信息以达到更好且更稳定的训练效果，同时在进行策略模型推断时可以仅利用局部信息，使得算法具有一定的扩展性。

CTDE 可以类比成一个足球队的训练和比赛过程：在训练时，11 个球员可以直接获得教练的指导从而完成球队的整体配合，而教练本身掌握着比赛全局信息，教练的指导也是从整支队、整场比赛的角度进行的；而训练好的 11 个球员在上场比赛时，则根据场上的实时情况直接做出决策，不再有教练的指导。

# 2. 多智能体和类似任务的状态设计

可以发现很多类似任务设计中，如果是比较复杂的状态，比如是数组的组合，复合数组等，都是“暴力”拼接、拉直的，类似 [[Machine Learning/MLP-ABC/06_其他机器学习技术#卷积神经网络\|CNN]] 中把最后提取的特征展平到 [[Machine Learning/MLP-ABC/02_神经网络\|MLP]] 一样，对人类来说这样做很难学到任何东西，但是对神经网络来说是有效的。

# 3. 多智能体编程技巧

这部分不是固定的，比如算法是 [[Reinforcement Learning/5_PPO\|PPO]]，只需要建立一个列表，装入若干 [[Reinforcement Learning/5_PPO\|PPO]] 算法即可，可以采取中心化训练，去中心化执行的方法：评论员网络接收全部智能体状态（或和动作，全部拼接、展平），每个智能体，仅采用它观察到的状态采取动作。

因此，进一步应该想到，每个智能体的状态应该单独给出，整理在一个表里输出作为总状态。并且在训练智能体的时候，善用 `enumerate()` 和 `zip()`，同时输出序号和内容，便于和不同智能体数据对应。

要注意的是，由于输出是包含多组智能体输出的，所以比单智能体操作不一样：在经验池采样一个批量只会，需要先转置，再把倒数第二维改成 tensor，相当于变成多个单智能体的状态，装在一个大列表中。

下面是一个例子

```python
# 环境给出的状态形式，每行代表某一时刻三个智能体的观测，这里假设是随机抽了三个时点数据作为一个批量，这三个时点对应三行

x = [[np.array([1, 2]), np.array([3, 4]), np.array([3, 5])],
     [np.array([4, 2]), np.array([0, 7]), np.array([5, 5])],
     [np.array([1, 5]), np.array([4, 7]), np.array([6, 2])],]
```

转置为

```python
[[array([1, 2]), array([4, 2]), array([1, 5])], 
 [array([3, 4]), array([0, 7]), array([4, 7])], 
 [array([3, 5]), array([5, 5]), array([6, 2])]]
```

再修改为

```python
[tensor([[1., 2.], [4., 2.], [1., 5.]]), 
 tensor([[3., 4.], [0., 7.], [4., 7.]]), 
 tensor([[3., 5.], [5., 5.], [6., 2.]])]
```

要实现该操作，可以参考以下函数写法

```python
def stack_array(x):
	rearranged = [[sub_x[i] for sub_x in x]
				  for i in range(len(x[0]))]
	return [
		torch.FloatTensor(np.vstack(aa)).to(device)
		for aa in rearranged
	]
```

