---
{"dg-publish":true,"permalink":"/personal-work/what-s-systematics/","dgPassFrontmatter":true,"created":"2024-01-10T10:29:37.381+08:00"}
---

# 系统科学、老三论和机器学习

>关于郭雷院士论文《系统学是什么》阅读总结。

# 1. 控制论和信息论

笔者本科时候对学业不太上心，闲人就容易产生天马行空的想法，于是特别想知道支撑现代科学的基础理论是什么，这样才第一次了解到“老三论”。老三论指系统论、控制论和信息论，本文主要是关于系统论的，但是暂时按下不表。

## 1.1. 控制论

控制论是现代控制的基本支撑，而笔者研究的深度强化学习也正是现代控制的一个重要方法。须知，当今社会大部分电气控制都是以控制论为理论基础的，比较经典的一个实际应用就包括阿波罗登月工程中应用的卡尔曼滤波器——试想，在 60、70 年代，在登月舱机载计算机的算力远远落后于现代任何一款计算机的情况下，依然能够实现稳定可靠的控制效果；除了传统控制，复杂网络、社会网络建模，动力学和博弈论也经常引入控制的思想，当然，这并非笔者熟悉的领域，故不展开。

笔者主要研究深度强化学习的应用，该方法适用于一阶马尔可夫决策过程的控制，即序贯决策问题，Sutton 在 1988 年提出时间差分算法，成为实施强化学习的基础支撑。

要理解“强化”的过程，可以类比人类的学习过程：如果做某件事会获得父母的奖励，我们就会倾向于多这样做，但很多事情不会有奖励，甚至如果挑食还会被批评。强化训练一个“智能体”也是这样：没有经验的时候只能随机探索，探索到了奖励，就有动机往这个方向继续探索，但是奖励往往是稀疏的，就像走迷宫，只有走到终点才有奖励，可能尝试很多次才会获得一次奖励，所以说奖励通常很稀疏。因此训练成本通常是很大的，*如何有效率地探索，并且在什么时候依靠经验做决策，成为优化强化算法的主要问题*。

直到现在，控制理论在强化学习算法的创新中也发挥着重要作用。“带有轨迹采样的概率集成”的强化学习方法，引入控制理论中的[模型预测控制](https://www.bilibili.com/video/BV1cL411n7KV/?spm_id_from=333.337.search-card.all.click)思想 ：通过在环境中采样到的轨迹去训练一个集成的神经网络，生成一个假环境模型，每次决策之前，先在假环境中模拟，选择一批较优决策序列，计算这批序列中首次决策的平均值作为真实决策，再用这个决策在真实环境中交互，大大降低了在虚拟或真实物理环境中仿真的成本。

## 1.2. 信息论

再粗浅聊一下信息论。生活中我们听到某个绯闻或者奇怪的事情，都会觉得“信息量”很大，这就是直觉上的信息熵：“太阳明天从东边升起”这件事发生的概率几乎是 100%，因此不会引起人们的重视；但是如果说“苹果公司停止生产手机”，就很容易引起关注，因为这件事发生的概率是很小的，即便这两句话的字数基本一样，写起来笔画也差不多，但是信息量是不一样的。

信息论不考虑一段消息的重要性或内在意义，因为这些是数据的质量问题而不是数据量，比如文本长度和可读性方面的问题。下面写一点枯燥的公式推导，香农的论文 [《通信的数学理论》](https://cdn.l7audiolab.com/wp-content/uploads/2022/06/%E9%80%9A%E4%BF%A1%E7%9A%84%E6%95%B0%E5%AD%A6%E7%90%86%E8%AE%BA.pdf)中首次提出信息熵，定义为
$$
H(X)=\mathbb{E}_x[I(x)]=\sum_{x\in\mathcal{X}}p(x)\mathrm{log}_2\left(\frac{1}{p(x)} \right)
$$
其中 $p$ 是概率密度函数，如果单位是比特，那么对数的底是 2，如果不强调单位，可以直接用自然常数 $e$ 为底。公式中 $\sum_{x\in\mathcal{X}}p(x)$ 可以写成期望形式，$\mathrm{log}(\frac{1}{p(x)})$，变成 $-\mathrm{log}p(x)$，式子化简为
$$
H(x)=\mathbb{E}_{x\sim p}[-\mathrm{log}~p(x)]
$$
对于 $-\mathrm{log}~ p(x)$ 来说，$p(x)$ 越小，函数值越大，这就和前面段落讲的信息论的感性理解契合了，事件发生概率越小，信息熵就越大：*信息熵是随机事件不确定性的度量*。可见信息熵的概念并不复杂，然而构成了现代信息技术的基础。

前面所说的，立意都太高，和控制理论一样，信息理论也在具体技术创新上有重要影响。仍然结合笔者熟悉的强化学习方法，有一个叫“软演员评论员”的算法，其主要改进是将在某状态$s$下选择某动作的概率 $p_{\theta}(a|s)$ 转化为动作熵 $-\mathrm{log}(p_{\theta}(a|s))$，作为正则项纳入目标函数，还在另一处创新地采用 KL 散度作为目标函数，使得该算法成为连续动作空间领域控制的 SOTA 算法。

# 2. 系统论

前面妄谈了一些控制论和信息论的内容，笔者粗略看过此二论的理论书籍和文献，其海量的数学推导和严谨冗长的证明过程都是让人望而生畏的，感慨于现代科学大厦根基之牢固。但笔者看系统论的资料时，画风突变：系统论几乎不涉及任何数学推导和证明，文字量巨大，有的全然是对各种科学方法的引用和思辨，亦不乏对哲学理念的论述和结合。系统论没有多少公式和证明，却最需要扎实的科学和哲学素养才能体会一二。

在学过马克思主义哲学以后，包括笔者在内的许多人可能都曾想过一个问题：为什么在没有相对论的时代，马克思可以提出比较科学的时空观念？唯物辩证法三大基本原理，对立统一、质量互变和否定之否定规律不仅在社会现象中体现，也在科学研究中反复体现。我们说马哲的一个重要贡献是给人们指出了正确的世界观和方法论，其立意仍然是特别高的，落实到科学问题上，我们似乎做的更多的是抽象、不断地抽象，而很少有思辨，大家都在说我发现了什么，而没有说为什么会发现，怎样做才更有可能发现。于是，大家都觉得科学和哲学的距离是很遥远的。

什么是系统科学？笔者认为很难用几句话来简单概括。美国的曼哈顿计划和中国的两弹一星计划可能是最能体现系统科学威力的里程碑事件。2023 年 8 月中国大陆上映的传记电影《奥本海默》向观众展现了深刻影响世界的曼哈顿计划：奥本海默和美国军方招募了物理、化学、数学等领域最优秀的专家，聚集在洛斯阿拉莫斯尝试制造原子弹，而奥本海默在参与计划前就已经系统规划了各个实验部门的设立方案，规划了铁路公路连接各个部门以实现协同。他并不是最优秀的核物理科学家，不是数学家，更不是化学专家，但他无疑具有强大的系统思考和系统规划能力——**不同领域的科学家有机结合在一起，可能发挥出改造世界的强大力量**。

![|550](https://s2.loli.net/2023/10/26/SgqALFUnlvX3CZV.jpg)

有人觉得曼哈顿计划和两弹一星计划属于管理学范畴的案例，但是单凭管理学理论，似乎远远无法达到这样的效果。钱学森是中国系统科学理论的主要开创者，提出系统科学的概念，党和国家领导人习近平也多次强调坚持系统观念统筹规划，笔者也更认可称这样的方法论为系统论，重点体现在系统思维上。这样的系统思维和系统方法，过去也许是一些天才依靠自己的知识储备、依靠大量实践，甚至是凭借自己独特的性格特点所体会出来的，但是显然，它并不是大众所拥有的特质。

一门学问，如果它的教育只能依靠言传身教，依靠不成文的、无法归纳的经验，那么是不能算作科学的，因此，系统科学的概念迫切需要拿到台面上来讲。

笔者认为，要真正进入系统科学的范畴，必须要有比较综合全面的理学基础，我们不会说钱学森和奥本海默是数学家或者化学家，但奥本海默本科时的确进修化学；钱学森不仅有工程理学硕士学位，还有航空学和数学哲学博士学位。

但是，人的精力的确是有限的，人们研究一门学科就需要花费大量的精力，要做到跨学科的科研，是非常困难的。就像系统科学学生的研究，也是有主线的，有的是微分方程，有的是理论物理，有的是博弈论，但是，如果能够做到在进行本领域研究的同时，还能够对其他科学领域保持一定的思考和理解，也就足够了，系统科学的确是需要具有跨学科研究能力的，但笔者认为最重要的是具备系统思维能力，这样才能使得个人的科研思想在发展中不断向“大集成”的方向进步。

那么，系统科学是不是仅仅指不同学科的交叉应用呢？笔者认为不能仅仅庸俗地、机械地把系统科学看成是类似物理理论和应用数学的交叉。在郭院士的论文中，将复杂性定义为“平衡”，“系统中成对要素之间的平衡是其秩序之本，而非平衡则是运动变化之源。”如果把这一理念拓展到跨学科领域，笔者认为，培养系统观念，要掌握的是不同学科领域的运动、变化和交互规律，即我们并不是因为二者结合起来有用所以结合，而是因为这样的结合恰恰能诞生一种新的理解，这种理解单从任意一者的角度都是无法得到的。

此外，笔者认为科学研究还应有批判精神和敬畏精神。批判，不等于对其他科学成果的贬低，而是辩证思想应有之义；敬畏，不等于对其他科学成果的敬而远之。这更像像毛泽东“战术上重视，战略上藐视”的精神：如前面所说，没有人一开始就具有丰富的知识储备，因此必然是从一条主线开始，我们要做的是尽可能地管中窥豹，可见一斑，尽量将不同的学科、不同的要素有机结合起来，对于庞大的知识体系要敢于拆分，敢于统一，迎难而上，将复杂的问题拆分成若干成分和要素，往往也能逐个击破，再统一起来达成总目的。

每当我们在学习中取得某种进展，霎时间觉得云淡风轻，问题迎刃而解，但是过一段时间回顾时，可能又觉得模棱两可，因此要保持敬畏的精神。比如某位学者提出某种新的方法，我们不仅看到它的效果不错，而且也能够推导它的计算过程，觉得这种方法并不困难，这是不错的，但是系统思维还提醒我们多想一步，要求我们多想想这位学者是如何创新的，敬畏感通常是在这里产生的。

郭院士的论文非常具有前瞻性，很难想象这是一篇 2016 年发表的论文，笔者结合在机器学习领域的知识储备产生许多体会。在论文第一部分，郭院士认为系统论超越还原论可以从三个方面来结合考虑，这里作引用：

> 一是整体指导下的还原与还原基础上的综合相结合 （ 或 “ 自上而下 ” 与 “ 自下而上 ” 方法相结合） ；二是机理分析与功能模拟相结合；三是系统认知与系统调控相结合

“自上而下”与“自下而上”的结合，在强化学习中的应用，就体现在环境奖励机制的设计和智能体的观测设计中，一个是宏观如何制定规则，一个是微观如何做特征选择，这两者在实践中常常被割裂开来看待，导致实验效果不佳。对于第二点，笔者也有所体会，即笔者的数学功底有限，因此许多问题从机理分析的角度经常感到非常棘手，然而通过编程模拟各个部分的功能，再加以统一组合，往往可以先给出模拟结果，再反推机理，大幅提高了研究问题的效率。

接下来，郭院士提到系统功能的“涌现”机制，这就不得不如让人想到 2022 年底出现至今热度不减的 ChatGPT。众所周知，这是当今自然语言处理（NLP）领域的最先进成果，然而其诞生的过程却很少被人们关注。在过去十几年里，NLP 发展比较平缓，谷歌等许多国内外大厂都投入大量资金在 BERT 模型中，OpenAI 公司则尝试 GPT 这一技术路线，他们所做的无非是持续加大硬件投入，持续增加训练数据，持续扩大模型参数，通常我们会认为，模型的语言能力是随着投入的加大线性增加的，然而在参数达到某个数量级时，其语言能力却发生了质的飞跃，这便是涌现机制。

举例来说，BIG-G 是一种具有仅解码器 Transformer 架构的语言模型，此外，emoji_movie 是 BIG 基准测试中的一项任务，其中一系列表情符号描述了一部特定的电影，任务是根据 Emoji 表情序列猜测电影，其特征和标签示例如下图。

![|380](https://s2.loli.net/2023/10/26/y5UhZDTxGE1nFjv.jpg)

下面我们可以看到 BIG-G 在不同尺度的 emoji_movie 上的表现。

![|625](https://s2.loli.net/2023/10/26/SPmOGye2jvrM4ib.jpg)

可以看到，当有效参数量级达到 $10^{10}$ 以上时，继续加大参数规模使得模型的识别能力发生指数级增强。

在深度学习中，模型的设计结构是容易掌握的，但是我们仍然称之为黑箱，因为我们只能观察到神经元对数据的最终反应结果，而不知道它为什么会这样反应，我们可以用神经网络拟合任意函数，但是无法彻底认知其机理。但另一方面，我们同样也可以用这样的黑箱轻松实现建模或者功能表达。

# 3. 总结

郭院士的论文还在许多方面做了阐述，但笔者的眼界仍然非常有限，仅仅产生一些小的具体的体会。笔者认为，系统论本身也绝非纯文字的、没有数学支撑的“科学哲学”，相反，系统论的确是可能实现现代科学与哲学连接的重要桥梁。系统论对我们当前的指导，就在于我们进行科学研究的时候，注意把培养系统思维放在极为重要的位置，作为理学院的学生，在研究具体问题的时候，就始终要提醒自己把所学知识与现代科学全局相联系，依据这样的方法论，才能指导我们始终在科研路上保持创新思维和充足动力。