---
{"dg-publish":true,"permalink":"/mlp-abc/03/","dgPassFrontmatter":true}
---

# 一般情况

在现成的机器学习框架中，一般都比较友好地给出了模型返回的一些数据，并且可以方便地作图。此外也可以采用 F 1 分数，PR 图像或者 AUC 图像来衡量模型质量，但是它们通常用于传统机器学习中，在深度学习领域比较少见，因此不在这里介绍。

在前面的机器学习任务代码中，如果我们在后面运行命令：

``` python
pd.DataFrame(history.history).plot() plt.grid(True)
plt.gca().set_ylim(0, 1) plt.show()
```

大概会得到类似下面的图像，$loss$ 是训练损失，$val\_loss$ 是验证损失，$loss$ 降低或 $accuracy$ 增加就是比较正常的，这些指标最终会趋于稳定。

<figure>
<img src="https://s2.loli.net/2023/08/28/TQEfItWzbFSBa4y.jpg"/>
<figcaption>图 3.1：两种任务的结果可视化</figcaption>
</figure>

# 损失曲线剧烈震荡

有时候会出现剧烈震荡，很有可能是因为学习率太大，例如要从 5 调整到 4，但是学习率比较大，比如梯度是-10，学习率是 0.5，那么 $5-0.5×10=0$，不会收敛到 4，误差也就容易一直震荡下去，此时可以调节学习率，现在已经有很多方法可以智能调节学习率，最常用的是 adam 方法，还有牛顿法等，最基本的 SGD 方法的学习率一般是固定的，大部分方法在现有的机器学习框架中可以轻松调用。

# 确定基准

如何判断 $loss$ 是大是小呢，这就需要添加一个基准，例如在 [[MLP-ABC/02_神经网络\|02_神经网络]] 第二节中，基准是用最小二乘法回归的一条直线，在二分类任务中，就算我们盲猜结果，大约也会获得 0.5 的正确率，因此 0.5 就是基准，如果模型的准确率接近 0.5，那就说明没有起到优化的作用。

# 过拟合和欠拟合

<figure>
<img src="https://s2.loli.net/2023/08/27/QhxLIDJnUZFiMm6.jpg"/>
<figcaption>图 3.2：两种任务的结果可视化</figcaption>
</figure>

如果验证损失明显大于训练损失，说明模型过拟合了，上面的图在 [[MLP-ABC/02_神经网络\|02_神经网络]]出现过，我们只需要两条大致的直线来拟合数据，而不需要穿过所有的点，如果过拟合了，建议减少神经元个数和层数，因为神经元越多，拟合线越多，层数越大，拟合维度越高，也可以用特殊方法调整权重的初始化值，这些方法可以在 Pytorch 或者 Tensorflow 的文档中找到，在[[MLP-ABC/04_模型改进技术\|04_模型改进技术]]中有简单提及。

如果 $loss$ 比较大，说明欠拟合，也就是效果不佳，在训练集和验证集中都有比较大的 $loss$，判断它比较大要依靠基准来对比，参考上一节，你可以增加神经元个数和层数，模型是否调整到位，就要依靠验证集数据来评估。

# 调整图像

训练集的结果与验证集不是完全同步的，训练误差是使用每个轮次的运行平均值计算的，验证误差是在训练集训练完毕之后，在验证集上测试得到的，虽然测试和验证都是在同一个迭代中完成，但是可以说验证集的$val\_loss$或$val\_accuracy$比测试集的要晚大约半个回合，通常我们不会做特殊处理，但你也的确可以做特殊处理，即把测试集数据前移半个回合，此时两者在训练刚开始的时候的损失曲线应该完全重合。

图像是否美观也很重要，模型的效果好也要通过图像表现出来，这就要求你具备良好的调用`matplotlib`包的能力，此外还有`seaborn`包，它在前者基础上构建，可以比较轻松地画出更美观的图像。

除了python的包，有时候你甚至可以用Photoshop或者其他绘画软件来作图或者改图，但是不要用它们绘制虚假数据图像。